import gradio as gr
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import functools

# =========================================================================
# 1. å®šä¹‰ CycleGAN çš„ç”Ÿæˆå™¨ç½‘ç»œç»“æ„ (ResNetGenerator)
#    è¿™æ˜¯ä¸ºäº†è®©ä»£ç ä¸ä¾èµ–å¤–éƒ¨ models æ–‡ä»¶å¤¹ï¼Œç›´æ¥åœ¨è¿™é‡ŒæŠŠç½‘ç»œâ€œç”»â€å‡ºæ¥
# =========================================================================
class ResnetGenerator(nn.Module):
    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.InstanceNorm2d, use_dropout=False, n_blocks=9, padding_type='reflect'):
        super(ResnetGenerator, self).__init__()
        if type(norm_layer) == functools.partial:
            use_bias = norm_layer.func == nn.InstanceNorm2d
        else:
            use_bias = norm_layer == nn.InstanceNorm2d

        model = [nn.ReflectionPad2d(3),
                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),
                 norm_layer(ngf),
                 nn.ReLU(True)]

        n_downsampling = 2
        for i in range(n_downsampling):  # ä¸‹é‡‡æ ·
            mult = 2 ** i
            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),
                      norm_layer(ngf * mult * 2),
                      nn.ReLU(True)]

        mult = 2 ** n_downsampling
        for i in range(n_blocks):       # ResNet æ¨¡å—
            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]

        for i in range(n_downsampling): # ä¸Šé‡‡æ ·
            mult = 2 ** (n_downsampling - i)
            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),
                                         kernel_size=3, stride=2,
                                         padding=1, output_padding=1,
                                         bias=use_bias),
                      norm_layer(int(ngf * mult / 2)),
                      nn.ReLU(True)]
        model += [nn.ReflectionPad2d(3)]
        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]
        model += [nn.Tanh()]

        self.model = nn.Sequential(*model)

    def forward(self, input):
        return self.model(input)

class ResnetBlock(nn.Module):
    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):
        super(ResnetBlock, self).__init__()
        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)

    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):
        conv_block = []
        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)

        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]
        if use_dropout:
            conv_block += [nn.Dropout(0.5)]

        p = 0
        if padding_type == 'reflect':
            conv_block += [nn.ReflectionPad2d(1)]
        elif padding_type == 'replicate':
            conv_block += [nn.ReplicationPad2d(1)]
        elif padding_type == 'zero':
            p = 1
        else:
            raise NotImplementedError('padding [%s] is not implemented' % padding_type)
        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]

        return nn.Sequential(*conv_block)

    def forward(self, x):
        return x + self.conv_block(x)

# =========================================================================
# 2. åç«¯æ¨ç†å¼•æ“ (ä¿®æ”¹ä¸ºç›´æ¥è°ƒç”¨ä¸Šé¢çš„ç±»ï¼Œä¸å†ä¾èµ– models æ–‡ä»¶å¤¹)
# =========================================================================
class CycleGANInference:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {self.device}")

        # è¿™é‡Œåˆå§‹åŒ–ä¸¤ä¸ªç”Ÿæˆå™¨
        # input_nc=3, output_nc=3 æ˜¯ RGB å›¾ç‰‡çš„æ ‡å‡†é…ç½®
        # n_blocks=9 æ˜¯ 256x256 å›¾ç‰‡çš„æ ‡å‡† CycleGAN é…ç½®
        self.netG_h2z = ResnetGenerator(3, 3, n_blocks=9).to(self.device)
        self.netG_a2o = ResnetGenerator(3, 3, n_blocks=9).to(self.device)
        
        # åŠ è½½æƒé‡
        # âš ï¸ è¯·ç¡®ä¿è¿™é‡Œçš„æ–‡ä»¶è·¯å¾„å’Œä½ å·¦ä¾§ç›®å½•é‡Œçš„æ–‡ä»¶åå®Œå…¨ä¸€è‡´ âš ï¸
        self.load_weights(self.netG_h2z, "model/horse2zebra.pth")
        self.load_weights(self.netG_a2o, "model/apple2orange.pth")

        # é¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((256, 256), Image.BICUBIC),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

    def load_weights(self, model, path):
        try:
            print(f"æ­£åœ¨åŠ è½½æƒé‡: {path}")
            state_dict = torch.load(path, map_location=self.device)
            
            # å¤„ç† state_dict çš„ key å¯èƒ½ä¸åŒ¹é…çš„é—®é¢˜ (ä¾‹å¦‚å¤šäº† 'module.' å‰ç¼€)
            if hasattr(state_dict, '_metadata'):
                del state_dict._metadata
            
            # è¿‡æ»¤æ‰ running_mean å’Œ running_varï¼Œå› ä¸º InstanceNorm2d é»˜è®¤ä¸è·Ÿè¸ªè¿™äº›ç»Ÿè®¡ä¿¡æ¯
            new_state_dict = {
                k: v for k, v in state_dict.items() 
                if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k
            }
            
            # æœ‰äº›ä¿å­˜çš„æ¨¡å‹ä¼šæŠŠ G å’Œ D æ”¾åœ¨ä¸€èµ·ï¼Œæˆ–è€…æœ‰å¤–å±‚åŒ…è£…ï¼Œè¿™é‡Œåšä¸ªç®€å•çš„é€‚é…
            # å¦‚æœä½ çš„pthé‡Œç›´æ¥å°±æ˜¯ç½‘ç»œå‚æ•°ï¼Œè¿™è¡Œé€šå¸¸èƒ½ç›´æ¥è·‘é€š
            model.load_state_dict(new_state_dict, strict=False) 
            model.eval()
            print(f"âœ… æˆåŠŸåŠ è½½: {path}")
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥ {path}: {e}")
            print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€… .pth æ–‡ä»¶æ˜¯å¦æŸåã€‚")

    def predict(self, input_img, mode):
        if input_img is None: return None
        
        # é€‰æ‹©æ¨¡å‹
        if "é©¬" in mode:
            model = self.netG_h2z
        else:
            model = self.netG_a2o

        # é¢„å¤„ç†
        img_tensor = self.transform(input_img).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            output_tensor = model(img_tensor)
            
        # åå¤„ç†
        output_img = output_tensor.squeeze(0).cpu().float().numpy()
        output_img = (output_img + 1) / 2.0 * 255.0
        import numpy as np
        output_img = np.transpose(output_img, (1, 2, 0))
        return output_img.clip(0, 255).astype(np.uint8)

# åˆå§‹åŒ–
engine = CycleGANInference()

# =========================================================================
# 3. å‰ç«¯ Gradio ç•Œé¢
# =========================================================================
with gr.Blocks(css=".fixed-height { height: 350px; }") as demo:
    gr.Markdown("## CycleGAN é£æ ¼è¿ç§»æ¼”ç¤º")
    
    with gr.Row():
        mode_selector = gr.Radio(
            choices=["é©¬ ğŸ â†’ æ–‘é©¬ ğŸ¦“", "è‹¹æœ ğŸ â†’ æ©™å­ ğŸŠ"], 
            value="é©¬ ğŸ â†’ æ–‘é©¬ ğŸ¦“", 
            label="é€‰æ‹©è½¬æ¢æ¨¡å¼"
        )

    with gr.Row():
        with gr.Column():
            input_view = gr.Image(type="pil", label="åŸå§‹å›¾ç‰‡", elem_classes="fixed-height", height=350)
        with gr.Column():
            output_view = gr.Image(type="pil", label="è½¬æ¢ç»“æœ", elem_classes="fixed-height", height=350, interactive=False)

    run_btn = gr.Button("ğŸš€ å¼€å§‹è½¬æ¢", variant="primary", size="lg")
    
    run_btn.click(
        fn=engine.predict,
        inputs=[input_view, mode_selector],
        outputs=output_view
    )

if __name__ == "__main__":
    demo.launch()